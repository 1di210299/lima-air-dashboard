# Lima Air Quality Dashboard

## ğŸ¯ DescripciÃ³n del Proyecto

Dashboard completo para el monitoreo de la calidad del aire en Lima, PerÃº. Sistema que integra datos histÃ³ricos del gobierno peruano con informaciÃ³n en tiempo real de OpenAQ API para proporcionar anÃ¡lisis predictivo y alertas tempranas.

## ğŸ“Š Estado del Proyecto

### âœ… Fase 1: Ingesta y Almacenamiento de Datos (COMPLETADA)
- **Base de datos configurada**: PostgreSQL para producciÃ³n, SQLite para desarrollo
- **ETL Pipeline funcionando**: Procesamiento automÃ¡tico de grandes volÃºmenes de datos
- **Sistema de descarga automÃ¡tica**: IntegraciÃ³n con OpenAQ API y datos del gobierno
- **ValidaciÃ³n de datos**: DetecciÃ³n de outliers y filtrado de datos invÃ¡lidos
- **Logging completo**: Seguimiento de todos los procesos de ingesta

#### Resultados Obtenidos:
- **Dataset principal**: 927,999 registros consolidados (2010-2024)
- **Ãšltima ejecuciÃ³n ETL**: 208,545 registros procesados en 46.39 segundos
- **Tasa de Ã©xito**: 99.5% (207,589 insertados + 956 actualizados)
- **Estaciones activas**: 4 estaciones registradas y funcionando

### ğŸš€ Siguientes Fases:
2. **Preprocesamiento y limpieza**
3. **Modelado y predicciÃ³n ML**
4. **API Backend**
5. **Dashboard Web**
6. **Sistema de notificaciones**
7. **Despliegue y producciÃ³n**

## ğŸ—ï¸ Arquitectura del Sistema

```
lima-air-dashboard/
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ database/          # Modelos y conexiones de BD
â”‚   â”‚   â”œâ”€â”€ models.py      # Esquemas SQLAlchemy
â”‚   â”‚   â””â”€â”€ connection.py  # GestiÃ³n de conexiones
â”‚   â””â”€â”€ data_ingestion/    # Pipeline de ingesta
â”‚       â”œâ”€â”€ etl.py         # Procesamiento ETL
â”‚       â””â”€â”€ downloader.py  # Descarga automÃ¡tica
â”œâ”€â”€ config/
â”‚   â””â”€â”€ settings.py        # ConfiguraciÃ³n del sistema
â”œâ”€â”€ data/
â”‚   â””â”€â”€ lima_air_quality_complete.csv  # Dataset principal
â”œâ”€â”€ logs/                  # Logs del sistema
â””â”€â”€ requirements.txt       # Dependencias
```

## ğŸ”§ InstalaciÃ³n y ConfiguraciÃ³n

### Prerrequisitos
```bash
Python 3.11+
PostgreSQL (opcional, usa SQLite por defecto)
```

### InstalaciÃ³n
```bash
# Clonar repositorio (cuando estÃ© en Git)
cd lima-air-dashboard

# Instalar dependencias
pip install -r requirements.txt

# Configurar base de datos
python -c "from src.database.connection import DatabaseManager; DatabaseManager().init_database()"
```

## ğŸš€ Uso del Sistema

### EjecuciÃ³n Manual del ETL
```bash
# Procesamiento completo del dataset
python src/data_ingestion/etl.py

# Descarga e ingesta automÃ¡tica (horaria)
python src/data_ingestion/downloader.py
```

### Tareas de VS Code
- **ETL - Procesamiento Completo**: Procesa todo el dataset principal
- **Ingesta de Datos - Horaria**: Descarga datos nuevos cada hora

## ğŸ“ˆ CaracterÃ­sticas Principales

### Sistema de Ingesta
- âœ… **MÃºltiples fuentes**: OpenAQ API + datos gubernamentales
- âœ… **Procesamiento por chunks**: Manejo eficiente de datasets grandes
- âœ… **ValidaciÃ³n automÃ¡tica**: Filtrado de outliers y datos invÃ¡lidos
- âœ… **DeduplicaciÃ³n**: PrevenciÃ³n de registros duplicados
- âœ… **Fallback automÃ¡tico**: Usa datos locales si API falla

### Base de Datos
- âœ… **Esquema optimizado**: Ãndices para consultas rÃ¡pidas
- âœ… **Time series**: Tablas especializadas para anÃ¡lisis temporal
- âœ… **Metadata tracking**: Registro completo de procesos de ingesta
- âœ… **Bulk operations**: InserciÃ³n eficiente de grandes volÃºmenes

### Monitoreo y Logs
- âœ… **Logging estructurado**: Seguimiento detallado de todos los procesos
- âœ… **MÃ©tricas de rendimiento**: Tiempos de ejecuciÃ³n y throughput
- âœ… **Reporte de errores**: IdentificaciÃ³n y manejo de problemas

## ğŸ“Š EstadÃ­sticas del Dataset

| MÃ©trica | Valor |
|---------|--------|
| **Total de registros** | 927,999 |
| **PerÃ­odo temporal** | 2010-2024 (14+ aÃ±os) |
| **Estaciones monitoreadas** | 10 estaciones |
| **ParÃ¡metros principales** | PM2.5, PM10, SO2, NO2, O3, CO |
| **Tasa de completitud** | ~85% |
| **Frecuencia de mediciÃ³n** | Horaria |

## ğŸ” Calidad de Datos

### Validaciones Implementadas
- **Rangos vÃ¡lidos**: PM2.5 â‰¥ 0, coordenadas dentro de Lima
- **DetecciÃ³n de outliers**: MÃ©todo IQR para valores extremos
- **Consistencia temporal**: ValidaciÃ³n de timestamps
- **Integridad de estaciones**: VerificaciÃ³n de metadatos

### Limpieza Aplicada
- EliminaciÃ³n de duplicados por timestamp y estaciÃ³n
- Filtrado de valores negativos o imposibles
- NormalizaciÃ³n de nombres de estaciones
- EstandarizaciÃ³n de coordenadas geogrÃ¡ficas

## ğŸ› ï¸ ConfiguraciÃ³n Avanzada

### Variables de Entorno
```bash
# Base de datos
DATABASE_URL=postgresql://user:pass@localhost/lima_air
# o SQLite (por defecto)
DATABASE_URL=sqlite:///lima_air_quality.db

# APIs
OPENAQ_API_KEY=tu_api_key_aqui
```

### PersonalizaciÃ³n ETL
Editar `config/settings.py` para ajustar:
- TamaÃ±o de chunks de procesamiento
- Umbrales de validaciÃ³n
- Frecuencia de descarga
- RetenciÃ³n de logs

## ğŸ“ PrÃ³ximos Pasos

### Fase 2: Preprocesamiento (En desarrollo)
- [ ] Pipeline de limpieza avanzada
- [ ] ImputaciÃ³n de valores faltantes
- [ ] Agregaciones temporales (diaria, semanal, mensual)
- [ ] Features derivadas (estacionalidad, tendencias)
- [ ] NormalizaciÃ³n para ML

### PlanificaciÃ³n TÃ©cnica
1. **AnÃ¡lisis exploratorio**: Patrones estacionales y tendencias
2. **Feature engineering**: Variables meteorolÃ³gicas y temporales
3. **PreparaciÃ³n para ML**: Datasets de entrenamiento y validaciÃ³n

## ğŸ¤ ContribuciÃ³n

Este proyecto estÃ¡ en desarrollo activo. Para contribuir:
1. Fork el repositorio
2. Crear rama feature (`git checkout -b feature/nueva-funcionalidad`)
3. Commit cambios (`git commit -am 'Agregar nueva funcionalidad'`)
4. Push a la rama (`git push origin feature/nueva-funcionalidad`)
5. Crear Pull Request

## ğŸ“„ Licencia

[Pendiente definir licencia]

---

**Ãšltima actualizaciÃ³n**: Agosto 2025  
**Estado**: Fase 1 completada âœ… | Fase 2 en desarrollo ğŸš§
